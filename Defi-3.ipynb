{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae74b0b8-d088-445f-8ff5-ad084305f270",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "# --------------------\n",
    "from sklearn.feature_extraction.text import  TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "import math\n",
    "import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2c5a07e-a7a0-497e-950a-9ddc1d338703",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_defi3.csv.gz',compression=\"gzip\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae89c2e5-521a-45fb-b61e-77505ae23505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23514 entries, 0 to 23513\n",
      "Data columns (total 3 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   Libellé.Prescription  23514 non-null  object \n",
      " 1   Avis.Pharmaceutique   23141 non-null  object \n",
      " 2   PLT                   23514 non-null  float64\n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 551.2+ KB\n",
      "None\n",
      "[ 5.3  4.1  3.1 10.   1.2  1.1  5.1  8.5  6.4  2.2 11.   8.4  6.2  4.2\n",
      "  9.1  8.1  8.3  6.1  3.2  2.4  8.2  5.2  1.3  2.1  6.3  7. ]\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "print(df.info())\n",
    "print(df['PLT'].unique())\n",
    "print(df['PLT'].nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e18b6280-e6f5-4694-a410-fd84c32f84d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a4c3137-f529-4221-b9fa-addbd6259ced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div id=ecb9f6ea-45c7-41ec-9f65-2f3b5de75fde style=\"display:none; background-color:#9D6CFF; color:white; width:200px; height:30px; padding-left:5px; border-radius:4px; flex-direction:row; justify-content:space-around; align-items:center;\" onmouseover=\"this.style.backgroundColor='#BA9BF8'\" onmouseout=\"this.style.backgroundColor='#9D6CFF'\" onclick=\"window.commands?.execute('create-mitosheet-from-dataframe-output');\">See Full Dataframe in Mito</div> <script> if (window.commands.hasCommand('create-mitosheet-from-dataframe-output')) document.getElementById('ecb9f6ea-45c7-41ec-9f65-2f3b5de75fde').style.display = 'flex' </script> <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Libellé.Prescription</th>\n",
       "      <th>Avis.Pharmaceutique</th>\n",
       "      <th>PLT</th>\n",
       "      <th>Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CONTRAMAL 100 MG/ML, GOUTTES BUV (TRAMADOL)</td>\n",
       "      <td>30 12 16 indication</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IMOVANE 7.5 MG, CPR SÉCABLE (ZOPICLONE)</td>\n",
       "      <td>22 12 16 recommande imovane 3 75mg cp 1 coucher eb</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>COLCHICINE 1 MG, CPR SÉCABLE (COLCHICINE)</td>\n",
       "      <td>vue dfg recommande administrer 1mg 48h donnees gpr veuillez reevaluer prescription ab</td>\n",
       "      <td>1</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PANTOPRAZOLE 40 MG, CPR GASTRO-RÉSISTANT (EUPANTOL)</td>\n",
       "      <td>dose curative absence atcd gastrique retrouve recommande reduire posologie 20 mg jour</td>\n",
       "      <td>1</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VANCOMYCINE 500 mg 1x/j</td>\n",
       "      <td>posologie infrat veuillez reevaluer posologie proposons 30mg kg ab</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></div>"
      ],
      "text/plain": [
       "                                Libellé.Prescription  \\\n",
       "0        CONTRAMAL 100 MG/ML, GOUTTES BUV (TRAMADOL)   \n",
       "1            IMOVANE 7.5 MG, CPR SÉCABLE (ZOPICLONE)   \n",
       "2          COLCHICINE 1 MG, CPR SÉCABLE (COLCHICINE)   \n",
       "3  PANTOPRAZOLE 40 MG, CPR GASTRO-RÉSISTANT (EUPA...   \n",
       "4                            VANCOMYCINE 500 mg 1x/j   \n",
       "\n",
       "                                 Avis.Pharmaceutique  PLT  Length  \n",
       "0                                30 12 16 indication    1      26  \n",
       "1  22 12 16 recommande imovane 3 75mg cp 1 couche...    1      59  \n",
       "2  vue dfg recommande administrer 1mg 48h donnees...    1     113  \n",
       "3  dose curative absence atcd gastrique retrouve ...    1     108  \n",
       "4  posologie infrat veuillez reevaluer posologie ...    0      77  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acbf0013-b0f4-46f5-bb2f-26c5fbd18141",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5456926e-6e50-466f-8d5a-1da14fd2b393",
   "metadata": {},
   "outputs": [],
   "source": [
    "#unaccented_string = unidecode.unidecode(df['Avis.Pharmaceutique'][2])\n",
    "df['Avis.Pharmaceutique'] = df['Avis.Pharmaceutique'].apply(lambda x : unidecode.unidecode(x)) # Remove é etc and ponctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f588395-abfe-46f3-bcca-26ed623e5a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = [4,4.1,4.2,5,5.1,5.2,5.3,6.3,6.4]\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f7797c3-f16a-4e32-9540-4749fade1a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = [4,4.1,4.2,5,5.1,5.2,5.3,6.3,6.4]\n",
    "for x in df['PLT']:\n",
    "    if x not in chars:\n",
    "        df['PLT'].replace(x, 0,inplace=True)\n",
    "for c in chars:\n",
    "    df['PLT'].replace(c, 1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43d1749c-2576-44d5-bc3d-45d533a5d3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Length'] = df['Avis.Pharmaceutique'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9f2b910-1415-4eac-8d56-56b7e7a65b71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div id=81ba3af1-41bb-46d2-9289-fe27a361c4a0 style=\"display:none; background-color:#9D6CFF; color:white; width:200px; height:30px; padding-left:5px; border-radius:4px; flex-direction:row; justify-content:space-around; align-items:center;\" onmouseover=\"this.style.backgroundColor='#BA9BF8'\" onmouseout=\"this.style.backgroundColor='#9D6CFF'\" onclick=\"window.commands?.execute('create-mitosheet-from-dataframe-output');\">See Full Dataframe in Mito</div> <script> if (window.commands.hasCommand('create-mitosheet-from-dataframe-output')) document.getElementById('81ba3af1-41bb-46d2-9289-fe27a361c4a0').style.display = 'flex' </script> <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">Length</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PLT</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>18613.0</td>\n",
       "      <td>81.381722</td>\n",
       "      <td>42.408490</td>\n",
       "      <td>2.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>455.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>4528.0</td>\n",
       "      <td>88.431316</td>\n",
       "      <td>49.519892</td>\n",
       "      <td>6.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>323.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></div>"
      ],
      "text/plain": [
       "      Length                                                     \n",
       "       count       mean        std  min   25%   50%    75%    max\n",
       "PLT                                                              \n",
       "0.0  18613.0  81.381722  42.408490  2.0  51.0  73.0  102.0  455.0\n",
       "1.0   4528.0  88.431316  49.519892  6.0  54.0  75.0  115.0  323.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('PLT').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3d01768-b2af-4258-8bc1-305d01c1ce2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['Length'].plot(bins=40, kind='hist') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc5cbc12-669b-4e6d-92cc-2ad783bb7864",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)\n",
    "df['PLT'] = df['PLT'].apply(lambda x : math.floor(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8163a588-3cd9-4c7d-8512-ccc83b9e66de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(sen):\n",
    "    # Remove punctuations and numbers\n",
    "    sentence = re.sub('[^a-zA-Z0-9]', ' ', sen)\n",
    "\n",
    "    # Single character removal\n",
    "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
    "\n",
    "    # Removing multiple spaces\n",
    "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
    "\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c07613d5-1a59-43c3-ad6c-31f7dde8f4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Avis.Pharmaceutique'] = df['Avis.Pharmaceutique'].apply(lambda x : preprocess_text(x))\n",
    "df['Avis.Pharmaceutique'] = df['Avis.Pharmaceutique'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cacb834e-4691-4710-8d36-9211b797852e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_word = [\"a\",\"abord\",\"absolument\",\"afin\",\"ah\",\"ai\",\"aie\",\"aient\",\"aies\",\"ailleurs\",\"ainsi\",\"ait\",\"allaient\",\n",
    "             \"allo\",\"allons\",\"allô\",\"alors\",\"anterieur\",\"anterieure\",\"anterieures\",\"apres\",\"après\",\"as\",\"assez\",\n",
    "             \"attendu\",\"au\",\"aucun\",\"aucune\",\"aucuns\",\"aujourd\",\"aujourd'hui\",\"aupres\",\"auquel\",\"aura\",\"aurai\",\n",
    "             \"auraient\",\"aurais\",\"aurait\",\"auras\",\"aurez\",\"auriez\",\"aurions\",\"aurons\",\"auront\",\"aussi\",\"autant\",\n",
    "             \"autre\",\"autrefois\",\"autrement\",\"autres\",\"autrui\",\"aux\",\"auxquelles\",\"auxquels\",\"avaient\",\"avais\",\n",
    "             \"avait\",\"avant\",\"avec\",\"avez\",\"aviez\",\"avions\",\"avoir\",\"avons\",\"ayant\",\"ayez\",\"ayons\",\"b\",\"bah\",\n",
    "             \"bas\",\"basee\",\"bat\",\"beau\",\"beaucoup\",\"bien\",\"bigre\",\"bon\",\"boum\",\"bravo\",\"brrr\",\"c\",\"car\",\"ce\",\n",
    "             \"ceci\",\"cela\",\"celle\",\"celle-ci\",\"celle-là\",\"celles\",\"celles-ci\",\"celles-là\",\"celui\",\"celui-ci\",\n",
    "             \"celui-là\",\"celà\",\"cent\",\"cependant\",\"certain\",\"certaine\",\"certaines\",\"certains\",\"certes\",\"ces\",\n",
    "             \"cet\",\"cette\",\"ceux\",\"ceux-ci\",\"ceux-là\",\"chacun\",\"chacune\",\"chaque\",\"cher\",\"chers\",\"chez\",\"chiche\",\n",
    "             \"chut\",\"chère\",\"chères\",\"ci\",\"cinq\",\"cinquantaine\",\"cinquante\",\"cinquantième\",\"cinquième\",\"clac\",\"clic\",\n",
    "             \"combien\",\"comme\",\"comment\",\"comparable\",\"comparables\",\"compris\",\"concernant\",\"contre\",\"couic\",\n",
    "             \"crac\",\"d\",\"da\",\"dans\",\"de\",\"debout\",\"dedans\",\"dehors\",\"deja\",\"delà\",\"depuis\",\"dernier\",\"derniere\",\n",
    "             \"derriere\",\"derrière\",\"des\",\"desormais\",\"desquelles\",\"desquels\",\"dessous\",\"dessus\",\"deux\",\"deuxième\",\n",
    "             \"deuxièmement\",\"devant\",\"devers\",\"devra\",\"devrait\",\"different\",\"differentes\",\"differents\",\"différent\",\n",
    "             \"différente\",\"différentes\",\"différents\",\"dire\",\"directe\",\"directement\",\"dit\",\"dite\",\"dits\",\"divers\",\n",
    "             \"diverse\",\"diverses\",\"dix\",\"dix-huit\",\"dix-neuf\",\"dix-sept\",\"dixième\",\"doit\",\"doivent\",\"donc\",\"dont\",\n",
    "             \"dos\",\"douze\",\"douzième\",\"dring\",\"droite\",\"du\",\"duquel\",\"durant\",\"dès\",\"début\",\"désormais\",\"e\",\"effet\",\n",
    "             \"egale\",\"egalement\",\"egales\",\"eh\",\"elle\",\"elle-même\",\"elles\",\"elles-mêmes\",\"en\",\"encore\",\"enfin\",\"entre\",\"envers\",\"environ\",\"es\",\"essai\",\"est\",\"et\",\"etant\",\"etc\",\"etre\",\"eu\",\"eue\",\"eues\",\"euh\",\"eurent\",\"eus\",\"eusse\",\"eussent\",\"eusses\",\"eussiez\",\"eussions\",\"eut\",\"eux\",\"eux-mêmes\",\"exactement\",\"excepté\",\"extenso\",\"exterieur\",\"eûmes\",\"eût\",\"eûtes\",\"f\",\"fais\",\"faisaient\",\"faisant\",\"fait\",\"faites\",\"façon\",\"feront\",\"fi\",\"flac\",\"floc\",\"fois\",\"font\",\"force\",\"furent\",\"fus\",\"fusse\",\"fussent\",\"fusses\",\"fussiez\",\"fussions\",\"fut\",\"fûmes\",\"fût\",\"fûtes\",\"g\",\"gens\",\"h\",\"ha\",\"haut\",\"hein\",\"hem\",\"hep\",\"hi\",\"ho\",\"holà\",\"hop\",\"hormis\",\"hors\",\"hou\",\"houp\",\"hue\",\"hui\",\"huit\",\"huitième\",\"hum\",\"hurrah\",\"hé\",\"hélas\",\"i\",\"ici\",\"il\",\"ils\",\"importe\",\"j\",\"je\",\"jusqu\",\"jusque\",\"juste\",\"k\",\"l\",\"la\",\"laisser\",\"laquelle\",\"las\",\"le\",\"lequel\",\"les\",\"lesquelles\",\"lesquels\",\"leur\",\"leurs\",\"longtemps\",\"lors\",\"lorsque\",\"lui\",\"lui-meme\",\"lui-même\",\"là\",\"lès\",\"m\",\"ma\",\"maint\",\"maintenant\",\"mais\",\"malgre\",\"malgré\",\"maximale\",\"me\",\"meme\",\"memes\",\"merci\",\"mes\",\"mien\",\"mienne\",\"miennes\",\"miens\",\"mille\",\"mince\",\"mine\",\"minimale\",\"moi\",\"moi-meme\",\"moi-même\",\"moindres\",\"moins\",\"mon\",\"mot\",\"moyennant\",\"multiple\",\"multiples\",\"même\",\"mêmes\",\"n\",\"na\",\"naturel\",\"naturelle\",\"naturelles\",\"ne\",\"neanmoins\",\"necessaire\",\"necessairement\",\"neuf\",\"neuvième\",\"ni\",\"nombreuses\",\"nombreux\",\"nommés\",\"non\",\"nos\",\"notamment\",\"notre\",\"nous\",\"nous-mêmes\",\"nouveau\",\"nouveaux\",\"nul\",\"néanmoins\",\"nôtre\",\"nôtres\",\"o\",\"oh\",\"ohé\",\"ollé\",\"olé\",\"on\",\"ont\",\"onze\",\"onzième\",\"ore\",\"ou\",\"ouf\",\"ouias\",\"oust\",\"ouste\",\"outre\",\"ouvert\",\"ouverte\",\"ouverts\",\"o|\",\"où\",\"p\",\"paf\",\"pan\",\"par\",\"parce\",\"parfois\",\"parle\",\"parlent\",\"parler\",\"parmi\",\"parole\",\"parseme\",\"partant\",\"particulier\",\"particulière\",\"particulièrement\",\"pas\",\"passé\",\"pendant\",\"pense\",\"permet\",\"personne\",\"personnes\",\"peu\",\"peut\",\"peuvent\",\"peux\",\"pff\",\"pfft\",\"pfut\",\"pif\",\"pire\",\"pièce\",\"plein\",\"plouf\",\"plupart\",\"plus\",\"plusieurs\",\"plutôt\",\"possessif\",\"possessifs\",\"possible\",\"possibles\",\"pouah\",\"pour\",\"pourquoi\",\"pourrais\",\"pourrait\",\"pouvait\",\"prealable\",\"precisement\",\"premier\",\"première\",\"premièrement\",\"pres\",\"probable\",\"probante\",\"procedant\",\"proche\",\"près\",\"psitt\",\"pu\",\"puis\",\"puisque\",\"pur\",\"pure\",\"q\",\"qu\",\"quand\",\"quant\",\"quant-à-soi\",\"quanta\",\"quarante\",\"quatorze\",\"quatre\",\"quatre-vingt\",\"quatrième\",\"quatrièmement\",\"que\",\"quel\",\"quelconque\",\"quelle\",\"quelles\",\"quelqu'un\",\"quelque\",\"quelques\",\"quels\",\"qui\",\"quiconque\",\"quinze\",\"quoi\",\"quoique\",\"r\",\"rare\",\"rarement\",\"rares\",\"relative\",\"relativement\",\"remarquable\",\"rend\",\"rendre\",\"restant\",\"reste\",\"restent\",\"restrictif\",\"retour\",\"revoici\",\"revoilà\",\"rien\",\"s\",\"sa\",\"sacrebleu\",\"sait\",\"sans\",\"sapristi\",\"sauf\",\"se\",\"sein\",\"seize\",\"selon\",\"semblable\",\"semblaient\",\"semble\",\"semblent\",\"sent\",\"sept\",\"septième\",\"sera\",\"serai\",\"seraient\",\"serais\",\"serait\",\"seras\",\"serez\",\"seriez\",\"serions\",\"serons\",\"seront\",\"ses\",\"seul\",\"seule\",\"seulement\",\"si\",\"sien\",\"sienne\",\"siennes\",\"siens\",\"sinon\",\"six\",\"sixième\",\"soi\",\"soi-même\",\"soient\",\"sois\",\"soit\",\"soixante\",\"sommes\",\"son\",\"sont\",\"sous\",\"souvent\",\"soyez\",\"soyons\",\"specifique\",\"specifiques\",\"speculatif\",\"stop\",\"strictement\",\"subtiles\",\"suffisant\",\"suffisante\",\"suffit\",\"suis\",\"suit\",\"suivant\",\"suivante\",\"suivantes\",\"suivants\",\"suivre\",\"sujet\",\"superpose\",\"sur\",\"surtout\",\"t\",\"ta\",\"tac\",\"tandis\",\"tant\",\"tardive\",\"te\",\"tel\",\"telle\",\"tellement\",\"telles\",\"tels\",\"tenant\",\"tend\",\"tenir\",\"tente\",\"tes\",\"tic\",\"tien\",\"tienne\",\"tiennes\",\"tiens\",\"toc\",\"toi\",\"toi-même\",\"ton\",\"touchant\",\"toujours\",\"tous\",\"tout\",\"toute\",\"toutefois\",\"toutes\",\"treize\",\"trente\",\"tres\",\"trois\",\"troisième\",\"troisièmement\",\"trop\",\"très\",\"tsoin\",\"tsouin\",\"tu\",\"té\",\"u\",\"un\",\"une\",\"unes\",\"uniformement\",\"unique\",\"uniques\",\"uns\",\"v\",\"va\",\"vais\",\"valeur\",\"vas\",\"vers\",\"via\",\"vif\",\"vifs\",\"vingt\",\"vivat\",\"vive\",\"vives\",\"vlan\",\"voici\",\"voie\",\"voient\",\"voilà\",\"voire\",\"vont\",\"vos\",\"votre\",\"vous\",\"vous-mêmes\",\"vu\",\"vé\",\"vôtre\",\"vôtres\",\"w\",\"x\",\"y\",\"z\",\"zut\",\"à\",\"â\",\"ça\",\"ès\",\"étaient\",\"étais\",\"était\",\"étant\",\"état\",\"étiez\",\"étions\",\"été\",\"étée\",\"étées\",\"étés\",\"êtes\",\"être\",\"ô\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc8c946f-3e3a-4048-91d1-7bc19ad12a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Avis.Pharmaceutique'] = df['Avis.Pharmaceutique'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_word)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1cdd37fc-4139-41fc-9241-ae6fc82d9b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text_plt(df):\n",
    "    for x in df:\n",
    "        if x not in chars:\n",
    "            df.replace(x, 0,inplace=True)\n",
    "    for c in chars:\n",
    "        df.replace(c, 1,inplace=True)\n",
    "   # df = df.apply(lambda x : math.floor(x))\n",
    "    df.dropna(inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2cd31f63-31b4-4fd1-83d3-87272b993625",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_avis(df):\n",
    "    df = df.apply(lambda x : preprocess_text(x))\n",
    "    df = df.str.lower()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f8bb593f-48ca-48c8-8d5a-2bb097aa9119",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [78]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X_train \u001b[38;5;241m=\u001b[39m clean_avis(\u001b[43mX_test\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": [
    "X_train = clean_avis(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a2c133-f0c1-4663-8974-ee5b33e5fdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "bd28483f-f91e-4c99-aa30-c78151dcf3a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5363     0.0\n",
       "5207     1.0\n",
       "2969     0.0\n",
       "6328     0.0\n",
       "9004     1.0\n",
       "        ... \n",
       "6185     1.0\n",
       "1829     1.0\n",
       "19405    0.0\n",
       "381      0.0\n",
       "10836    1.0\n",
       "Name: PLT, Length: 6943, dtype: float64"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text_plt(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "f855333e-0628-469d-8712-703fcfd28221",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div id=e1da4142-25c6-4473-8e15-d6b1b43e75e6 style=\"display:none; background-color:#9D6CFF; color:white; width:200px; height:30px; padding-left:5px; border-radius:4px; flex-direction:row; justify-content:space-around; align-items:center;\" onmouseover=\"this.style.backgroundColor='#BA9BF8'\" onmouseout=\"this.style.backgroundColor='#9D6CFF'\" onclick=\"window.commands?.execute('create-mitosheet-from-dataframe-output');\">See Full Dataframe in Mito</div> <script> if (window.commands.hasCommand('create-mitosheet-from-dataframe-output')) document.getElementById('e1da4142-25c6-4473-8e15-d6b1b43e75e6').style.display = 'flex' </script> <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Libellé.Prescription</th>\n",
       "      <th>Avis.Pharmaceutique</th>\n",
       "      <th>PLT</th>\n",
       "      <th>Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CONTRAMAL 100 MG/ML, GOUTTES BUV (TRAMADOL)</td>\n",
       "      <td>30 12 16 indication</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IMOVANE 7.5 MG, CPR SÉCABLE (ZOPICLONE)</td>\n",
       "      <td>22 12 16 recommand imovane 3 75mg cp 1 coucher eb</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>COLCHICINE 1 MG, CPR SÉCABLE (COLCHICINE)</td>\n",
       "      <td>vue dfg recommand administrer 1mg 48h donn gpr veuillez valuer prescription ab</td>\n",
       "      <td>1</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PANTOPRAZOLE 40 MG, CPR GASTRO-RÉSISTANT (EUPANTOL)</td>\n",
       "      <td>dose curative absence atcd gastrique retrouv recommand duire posologie 20 mg jour</td>\n",
       "      <td>1</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VANCOMYCINE 500 mg 1x/j</td>\n",
       "      <td>posologie infrat veuillez valuer posologie proposons 30mg kg ab</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></div>"
      ],
      "text/plain": [
       "                                Libellé.Prescription  \\\n",
       "0        CONTRAMAL 100 MG/ML, GOUTTES BUV (TRAMADOL)   \n",
       "1            IMOVANE 7.5 MG, CPR SÉCABLE (ZOPICLONE)   \n",
       "2          COLCHICINE 1 MG, CPR SÉCABLE (COLCHICINE)   \n",
       "3  PANTOPRAZOLE 40 MG, CPR GASTRO-RÉSISTANT (EUPA...   \n",
       "4                            VANCOMYCINE 500 mg 1x/j   \n",
       "\n",
       "                                 Avis.Pharmaceutique  PLT  Length  \n",
       "0                                30 12 16 indication    1      26  \n",
       "1  22 12 16 recommand imovane 3 75mg cp 1 coucher eb    1      59  \n",
       "2  vue dfg recommand administrer 1mg 48h donn gpr...    1     113  \n",
       "3  dose curative absence atcd gastrique retrouv r...    1     108  \n",
       "4  posologie infrat veuillez valuer posologie pro...    0      77  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a79a2f-3681-4284-91a9-f15550f8b899",
   "metadata": {},
   "source": [
    "#### Frequency of word list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "0ac52dce-8b7e-4d68-92c1-677a132d7224",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "cv_fit = cv.fit_transform(df['Avis.Pharmaceutique'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "a233e912-168c-44df-bb06-fd8578cc56aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Casper\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('17', 7961),\n",
       " ('mg', 6268),\n",
       " ('jour', 3737),\n",
       " ('propose', 3479),\n",
       " ('hus', 3252),\n",
       " ('cp', 3038),\n",
       " ('01', 2931),\n",
       " ('02', 2790),\n",
       " ('proposons', 2776),\n",
       " ('03', 2262),\n",
       " ('reference', 2259),\n",
       " ('cpr', 2217),\n",
       " ('prescrire', 2176),\n",
       " ('refuse', 2040),\n",
       " ('posologie', 1972),\n",
       " ('motif', 1899),\n",
       " ('04', 1773),\n",
       " ('prescription', 1684),\n",
       " ('pantoprazole', 1591),\n",
       " ('andrea', 1532)]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list = cv.get_feature_names()\n",
    "count_list = cv_fit.toarray().sum(axis=0)\n",
    "dict_list = dict(zip(word_list,count_list))\n",
    "dict_list = sorted(dict_list.items(), key=lambda item: item[1],reverse=True)\n",
    "dict_list[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb1f28c-e079-4950-997e-ff15b5c71d0c",
   "metadata": {},
   "source": [
    "#### Simple Way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "352a468a-7f32-4a54-bff9-1a359b919a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('bow', CountVectorizer()),  # strings to token integer counts\n",
    "    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores\n",
    "    ('classifier', MultinomialNB()),  # train on TF-IDF vectors w/ Naive Bayes classifier\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "96f5dc70-050e-46b6-b5f0-0a6ae0d141d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['Avis.Pharmaceutique']\n",
    "y = df['PLT']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.3,random_state = 42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ea28b2db-9f95-4595-986c-ac391a5c6505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;bow&#x27;, CountVectorizer()), (&#x27;tfidf&#x27;, TfidfTransformer()),\n",
       "                (&#x27;classifier&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;bow&#x27;, CountVectorizer()), (&#x27;tfidf&#x27;, TfidfTransformer()),\n",
       "                (&#x27;classifier&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfTransformer</label><div class=\"sk-toggleable__content\"><pre>TfidfTransformer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('bow', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
       "                ('classifier', MultinomialNB())])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a3666ccc-bc04-4431-b605-ce8d285e64bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "44b734db-e2bc-4889-aedd-c433931e2b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5466  118]\n",
      " [ 638  721]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.98      0.94      5584\n",
      "           1       0.86      0.53      0.66      1359\n",
      "\n",
      "    accuracy                           0.89      6943\n",
      "   macro avg       0.88      0.75      0.80      6943\n",
      "weighted avg       0.89      0.89      0.88      6943\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,predictions))\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7b41bb0a-29a0-4454-89ed-9ad9bcc62544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5482  102]\n",
      " [ 614  745]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.98      0.94      5584\n",
      "           1       0.88      0.55      0.68      1359\n",
      "\n",
      "    accuracy                           0.90      6943\n",
      "   macro avg       0.89      0.76      0.81      6943\n",
      "weighted avg       0.90      0.90      0.89      6943\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,predictions))\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "050ccbab-ca1b-4833-9167-bbbc97a9c054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5467  117]\n",
      " [ 637  722]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.98      0.94      5584\n",
      "           1       0.86      0.53      0.66      1359\n",
      "\n",
      "    accuracy                           0.89      6943\n",
      "   macro avg       0.88      0.76      0.80      6943\n",
      "weighted avg       0.89      0.89      0.88      6943\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,predictions))\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "64b04448-e261-4918-bc65-1668f1eb0bcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f3d91f18-2e90-4a0f-9f05-c3bc3bba14f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "86966cf7-454a-4048-bd27-8d24a4e74d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#df['Avis.Pharmaceutique'].apply(lambda w : w for w in df['Avis.Pharmaceutique'].split() if not w in stop_word)\n",
    "#df['Avis.Pharmaceutique'] = df['Avis.Pharmaceutique'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_word)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838c99f0-0f35-4ec7-9ba5-7ae8aea2d4fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe394cbc-e2f1-4b36-bf1f-f450d1b2a475",
   "metadata": {},
   "source": [
    "#### DEEP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9ea8e57e-2121-4618-bee6-6316be68d386",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Casper\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "777cec13-aca7-4a39-9510-ded3f5c4b2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5651153d-8bac-4f90-b9ee-229db6ba42c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['Avis.Pharmaceutique']\n",
    "y = df['PLT']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "d66a2894-921e-47e2-b2b8-162c816701be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "corpus = X_train\n",
    "corpus_test = X_test\n",
    "all_words = []\n",
    "for sent in corpus:\n",
    "    tokenize_word = word_tokenize(sent)\n",
    "    for word in tokenize_word:\n",
    "        all_words.append(word)\n",
    "all_words_test = []       \n",
    "for sent in corpus_test:\n",
    "    tokenize_word = word_tokenize(sent)\n",
    "    for word in tokenize_word:\n",
    "        all_words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "b559ea48-98dc-4c50-a6d5-99c177cba294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47289"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "192ced33-0f08-413d-a17c-260e9d3d9c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7506\n"
     ]
    }
   ],
   "source": [
    "unique_words = set(all_words)\n",
    "unique_words_t = set(all_words_test)\n",
    "print(len(unique_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "177f04a2-dad0-434a-aaf6-c47c3d8fed7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_length = len(unique_words)\n",
    "vocab_length_t = len(unique_words_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "8aed3088-8af1-4b73-b558-8d809f4078f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "b079bbdd-d82a-4e96-89c0-a09846ef26f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_sentences = [one_hot(sent, vocab_length) for sent in corpus]\n",
    "embedded_sentences_t = [one_hot(sent, vocab_length_t) for sent in corpus_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "d11288fb-b8b3-4c38-af75-ca480a297df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count = lambda sentence: len(word_tokenize(sentence))\n",
    "longest_sentence = max(corpus, key=word_count)\n",
    "length_long_sentence = len(word_tokenize(longest_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "0480ffe5-d44f-4575-8e58-177e382a12a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_tokenize(longest_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ec2829-da54-4979-a449-ebc448c14c86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "2113665e-a337-48ce-8c3c-9b8e73d7386c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3539 7279 6009 ...    0    0    0]\n",
      " [7205  368 5322 ...    0    0    0]\n",
      " [1094 2877 1973 ...    0    0    0]\n",
      " ...\n",
      " [6470 4739 6382 ...    0    0    0]\n",
      " [2791 1657 2736 ...    0    0    0]\n",
      " [1094 4739 6382 ...    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "padded_sentences = pad_sequences(embedded_sentences, length_long_sentence, padding='post')\n",
    "padded_sentences_t = pad_sequences(embedded_sentences_t, length_long_sentence, padding='post')\n",
    "print(padded_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "2ba66d7f-8f70-4556-9b63-3d8c089dc1d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18512, 40)\n",
      "(4629, 40)\n"
     ]
    }
   ],
   "source": [
    "print(padded_sentences.shape)\n",
    "print(padded_sentences_t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "c23bafa2-1b7d-4b06-b642-38de02e17834",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Activation, Dropout, Dense\n",
    "from keras.layers import Flatten, LSTM\n",
    "from keras.layers import GlobalMaxPooling1D\n",
    "from keras.models import Model\n",
    "from keras.layers.embeddings import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "214ce619-d721-48db-b84e-8709ab373618",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_length, 20, input_length=length_long_sentence))\n",
    "model.add(Flatten())\n",
    "#model.add(Dense(120, activation='relu'))\n",
    "#model.add(Dropout(0.2))\n",
    "#model.add(Dense(units=60,activation='relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "#model.add(Dense(units=15,activation='relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "80a3f34b-d395-4f6e-a657-d8f27edcf2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "#print(model.summary())\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "911085d3-ce59-4437-a2a8-9647eb6071b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "579/579 [==============================] - 1s 2ms/step - loss: 0.3719A\n",
      "Epoch 2/50\n",
      "579/579 [==============================] - 1s 2ms/step - loss: 0.2175\n",
      "Epoch 3/50\n",
      "579/579 [==============================] - 1s 2ms/step - loss: 0.1649\n",
      "Epoch 4/50\n",
      "579/579 [==============================] - 1s 2ms/step - loss: 0.1319\n",
      "Epoch 5/50\n",
      "579/579 [==============================] - 1s 2ms/step - loss: 0.1032\n",
      "Epoch 6/50\n",
      "579/579 [==============================] - 1s 2ms/step - loss: 0.0832\n",
      "Epoch 7/50\n",
      "579/579 [==============================] - 2s 3ms/step - loss: 0.0699A: 0s\n",
      "Epoch 8/50\n",
      "579/579 [==============================] - 2s 3ms/step - loss: 0.0602\n",
      "Epoch 9/50\n",
      "579/579 [==============================] - 2s 3ms/step - loss: 0.0535\n",
      "Epoch 10/50\n",
      "579/579 [==============================] - 2s 3ms/step - loss: 0.0472\n",
      "Epoch 11/50\n",
      "579/579 [==============================] - 1s 2ms/step - loss: 0.0473\n",
      "Epoch 12/50\n",
      "579/579 [==============================] - 1s 2ms/step - loss: 0.0438\n",
      "Epoch 13/50\n",
      "579/579 [==============================] - 1s 2ms/step - loss: 0.0370A: \n",
      "Epoch 14/50\n",
      "579/579 [==============================] - 1s 2ms/step - loss: 0.0359\n",
      "Epoch 15/50\n",
      "579/579 [==============================] - 1s 2ms/step - loss: 0.0339\n",
      "Epoch 16/50\n",
      "579/579 [==============================] - 1s 2ms/step - loss: 0.0347\n",
      "Epoch 17/50\n",
      "579/579 [==============================] - 1s 2ms/step - loss: 0.0309\n",
      "Epoch 18/50\n",
      "579/579 [==============================] - 1s 2ms/step - loss: 0.0319\n",
      "Epoch 19/50\n",
      "579/579 [==============================] - 1s 2ms/step - loss: 0.0322A: 0s - loss: 0.03\n",
      "Epoch 20/50\n",
      "579/579 [==============================] - 1s 2ms/step - loss: 0.0313\n",
      "Epoch 21/50\n",
      "579/579 [==============================] - 1s 2ms/step - loss: 0.0281\n",
      "Epoch 22/50\n",
      "579/579 [==============================] - 1s 2ms/step - loss: 0.0261A: 0s\n",
      "Epoch 23/50\n",
      "579/579 [==============================] - 1s 2ms/step - loss: 0.0266\n",
      "Epoch 24/50\n",
      "579/579 [==============================] - 1s 2ms/step - loss: 0.0287\n",
      "Epoch 25/50\n",
      "579/579 [==============================] - 1s 2ms/step - loss: 0.0243\n",
      "Epoch 26/50\n",
      "579/579 [==============================] - 1s 2ms/step - loss: 0.0276\n",
      "Epoch 27/50\n",
      "579/579 [==============================] - 1s 2ms/step - loss: 0.0255\n",
      "Epoch 28/50\n",
      "579/579 [==============================] - 1s 2ms/step - loss: 0.0254\n",
      "Epoch 29/50\n",
      "579/579 [==============================] - 1s 2ms/step - loss: 0.0286\n",
      "Epoch 30/50\n",
      "579/579 [==============================] - 1s 2ms/step - loss: 0.0292\n",
      "Epoch 31/50\n",
      "579/579 [==============================] - 1s 2ms/step - loss: 0.0232\n",
      "Epoch 32/50\n",
      "579/579 [==============================] - 1s 2ms/step - loss: 0.0218\n",
      "Epoch 33/50\n",
      "579/579 [==============================] - 1s 2ms/step - loss: 0.0238\n",
      "Epoch 34/50\n",
      "579/579 [==============================] - 1s 2ms/step - loss: 0.0235\n",
      "Epoch 35/50\n",
      "579/579 [==============================] - 1s 2ms/step - loss: 0.0219\n",
      "Epoch 36/50\n",
      "579/579 [==============================] - 1s 2ms/step - loss: 0.0231\n",
      "Epoch 37/50\n",
      "579/579 [==============================] - 1s 2ms/step - loss: 0.0222\n",
      "Epoch 38/50\n",
      "579/579 [==============================] - 1s 2ms/step - loss: 0.0268\n",
      "Epoch 39/50\n",
      "579/579 [==============================] - 1s 2ms/step - loss: 0.0275A: 0s - loss: 0.0\n",
      "Epoch 40/50\n",
      "579/579 [==============================] - 1s 2ms/step - loss: 0.0237\n",
      "Epoch 41/50\n",
      "579/579 [==============================] - 1s 2ms/step - loss: 0.0222\n",
      "Epoch 42/50\n",
      "579/579 [==============================] - 1s 2ms/step - loss: 0.0220A: 0s - los\n",
      "Epoch 43/50\n",
      "579/579 [==============================] - 1s 2ms/step - loss: 0.0183A: 0s - lo\n",
      "Epoch 44/50\n",
      "579/579 [==============================] - 1s 2ms/step - loss: 0.0176\n",
      "Epoch 45/50\n",
      "579/579 [==============================] - 1s 2ms/step - loss: 0.0241\n",
      "Epoch 46/50\n",
      "579/579 [==============================] - 1s 2ms/step - loss: 0.0210\n",
      "Epoch 47/50\n",
      "579/579 [==============================] - 1s 2ms/step - loss: 0.0220\n",
      "Epoch 48/50\n",
      "579/579 [==============================] - 1s 2ms/step - loss: 0.0205\n",
      "Epoch 49/50\n",
      "579/579 [==============================] - 1s 2ms/step - loss: 0.0202\n",
      "Epoch 50/50\n",
      "579/579 [==============================] - 1s 2ms/step - loss: 0.0211\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x27bebc90df0>"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(padded_sentences, y_train, epochs=50,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "e22e973b-3bd0-46e8-9eed-4361a714f5fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable float object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [193]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m loss, accuracy \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(padded_sentences_t, y_test, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy: \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (accuracy\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m))\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot unpack non-iterable float object"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(padded_sentences_t, y_test, verbose=0)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "f0ca725c-51d4-4b9d-9a24-08b41a2065c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_argmax = (model.predict(padded_sentences_t) > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "e50f9cd4-3cd2-4283-8a38-98a16396690a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "c568a35d-7a34-4e78-9501-cbe9d21d8543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89      3723\n",
      "           1       0.00      0.00      0.00       906\n",
      "\n",
      "    accuracy                           0.80      4629\n",
      "   macro avg       0.40      0.50      0.45      4629\n",
      "weighted avg       0.65      0.80      0.72      4629\n",
      "\n",
      "[[3723    0]\n",
      " [ 906    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Casper\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Casper\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Casper\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions_argmax))\n",
    "print(confusion_matrix(y_test,predictions_argmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "e969c2bd-fb4a-40ac-931e-f47645423e0d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "no numeric data to plot",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [189]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m model_loss \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(model\u001b[38;5;241m.\u001b[39mhistory\u001b[38;5;241m.\u001b[39mhistory)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mmodel_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\plotting\\_core.py:972\u001b[0m, in \u001b[0;36mPlotAccessor.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    969\u001b[0m             label_name \u001b[38;5;241m=\u001b[39m label_kw \u001b[38;5;129;01mor\u001b[39;00m data\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m    970\u001b[0m             data\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m label_name\n\u001b[1;32m--> 972\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mplot_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\plotting\\_matplotlib\\__init__.py:71\u001b[0m, in \u001b[0;36mplot\u001b[1;34m(data, kind, **kwargs)\u001b[0m\n\u001b[0;32m     69\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124max\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(ax, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft_ax\u001b[39m\u001b[38;5;124m\"\u001b[39m, ax)\n\u001b[0;32m     70\u001b[0m plot_obj \u001b[38;5;241m=\u001b[39m PLOT_CLASSES[kind](data, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 71\u001b[0m \u001b[43mplot_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     72\u001b[0m plot_obj\u001b[38;5;241m.\u001b[39mdraw()\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m plot_obj\u001b[38;5;241m.\u001b[39mresult\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\plotting\\_matplotlib\\core.py:286\u001b[0m, in \u001b[0;36mMPLPlot.generate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_args_adjust()\n\u001b[1;32m--> 286\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_plot_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setup_subplots()\n\u001b[0;32m    288\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_plot()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\plotting\\_matplotlib\\core.py:453\u001b[0m, in \u001b[0;36mMPLPlot._compute_plot_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;66;03m# no non-numeric frames or series allowed\u001b[39;00m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_empty:\n\u001b[1;32m--> 453\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno numeric data to plot\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m numeric_data\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_to_ndarray)\n",
      "\u001b[1;31mTypeError\u001b[0m: no numeric data to plot"
     ]
    }
   ],
   "source": [
    "model_loss = pd.DataFrame(model.history.history)\n",
    "model_loss.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb82a29-5a18-42bd-8b22-7014155001d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f68d6e6-dade-4d72-82d0-97b3d52a4aff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e270ce9-1636-4872-a73d-a0ac8f70b2c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c62a8d9-2435-48ce-9996-ad7d7e7fa61e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8386fa85-fc0e-4806-8a35-57533e1077a8",
   "metadata": {},
   "source": [
    "#### XLNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b53d99f6-b50d-4ca0-a1cf-fa3f1bc4ff16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip uninstall torch torchvision -y\n",
    "#! pip install torch==1.6.0+cu101 torchvision==0.7.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "#! pip install -U transformers\n",
    "#! pip install -U simpletransformers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "87378418-524d-4e50-b18e-d3af0bcc18a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((18512, 2), (4629, 2))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# splitting the data into training and eval dataset\n",
    "X = df['Avis.Pharmaceutique']\n",
    "y = df['PLT']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "train_df = pd.DataFrame(X_train)\n",
    "train_df['PLT'] = y_train\n",
    "\n",
    "eval_df = pd.DataFrame(X_test)\n",
    "eval_df['PLT'] = y_test\n",
    "\n",
    "train_df.shape, eval_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fd305552-19d2-479e-aa30-f6efafc77066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nargs = {\\n   'output_dir': 'outputs/',\\n   'cache_dir': 'cache/',\\n   'fp16': True,\\n   'fp16_opt_level': 'O1',\\n   'max_seq_length': 256,\\n   'train_batch_size': 8,\\n   'eval_batch_size': 8,\\n   'gradient_accumulation_steps': 1,\\n   'num_train_epochs': 3,\\n   'weight_decay': 0,\\n   'learning_rate': 4e-5,\\n   'adam_epsilon': 1e-8,\\n   'warmup_ratio': 0.06,\\n   'warmup_steps': 0,\\n   'max_grad_norm': 1.0,\\n   'logging_steps': 50,\\n   'evaluate_during_training': False,\\n   'save_steps': 2000,\\n   'eval_all_checkpoints': True,\\n   'use_tensorboard': True,\\n   'overwrite_output_dir': True,\\n   'reprocess_input_data': False,\\n}\\n\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from simpletransformers.classification import ClassificationModel\n",
    "import pandas as pd\n",
    "import logging\n",
    "import sklearn\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "transformers_logger = logging.getLogger(\"transformers\")\n",
    "transformers_logger.setLevel(logging.WARNING)\n",
    "\n",
    "# They are lot of arguments to play with\n",
    "'''\n",
    "args = {\n",
    "   'output_dir': 'outputs/',\n",
    "   'cache_dir': 'cache/',\n",
    "   'fp16': True,\n",
    "   'fp16_opt_level': 'O1',\n",
    "   'max_seq_length': 256,\n",
    "   'train_batch_size': 8,\n",
    "   'eval_batch_size': 8,\n",
    "   'gradient_accumulation_steps': 1,\n",
    "   'num_train_epochs': 3,\n",
    "   'weight_decay': 0,\n",
    "   'learning_rate': 4e-5,\n",
    "   'adam_epsilon': 1e-8,\n",
    "   'warmup_ratio': 0.06,\n",
    "   'warmup_steps': 0,\n",
    "   'max_grad_norm': 1.0,\n",
    "   'logging_steps': 50,\n",
    "   'evaluate_during_training': False,\n",
    "   'save_steps': 2000,\n",
    "   'eval_all_checkpoints': True,\n",
    "   'use_tensorboard': True,\n",
    "   'overwrite_output_dir': True,\n",
    "   'reprocess_input_data': False,\n",
    "}\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fa761ce1-559d-4fbb-914d-4ba836826fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "18d6d7e6-9353-43e3-aab9-ff059d8322e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bc33cf58-eb46-4ccb-9b57-653220f9adf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.bias', 'lm_loss.weight']\n",
      "- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.bias', 'sequence_summary.summary.bias', 'logits_proj.weight', 'sequence_summary.summary.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 94.00 MiB (GPU 0; 2.00 GiB total capacity; 1.72 GiB already allocated; 0 bytes free; 1.73 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [38]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m ClassificationModel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxlnet\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxlnet-base-cased\u001b[39m\u001b[38;5;124m'\u001b[39m, args\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_train_epochs\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m4\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_batch_size\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m4\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_seq_length\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m40\u001b[39m}) \u001b[38;5;66;03m# You can set class weights by using the optional weight argument\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[0;32m      8\u001b[0m result, model_outputs, wrong_predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39meval_model(eval_df, acc\u001b[38;5;241m=\u001b[39msklearn\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39maccuracy_score)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\simpletransformers\\classification\\classification_model.py:553\u001b[0m, in \u001b[0;36mClassificationModel.train_model\u001b[1;34m(self, train_df, multi_label, output_dir, show_running_loss, args, eval_df, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    542\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    543\u001b[0m     os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(output_dir)\n\u001b[0;32m    544\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(output_dir)\n\u001b[0;32m    545\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39moverwrite_output_dir\n\u001b[0;32m    546\u001b[0m ):\n\u001b[0;32m    547\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    548\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput directory (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m) already exists and is not empty.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    549\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Set overwrite_output_dir: True to automatically overwrite.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    550\u001b[0m             output_dir\n\u001b[0;32m    551\u001b[0m         )\n\u001b[0;32m    552\u001b[0m     )\n\u001b[1;32m--> 553\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_move_model_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    555\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_hf_datasets:\n\u001b[0;32m    556\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39msliding_window:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\simpletransformers\\classification\\classification_model.py:2348\u001b[0m, in \u001b[0;36mClassificationModel._move_model_to_device\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2347\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_move_model_to_device\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m-> 2348\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:607\u001b[0m, in \u001b[0;36mModule.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    604\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m    605\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[1;32m--> 607\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:354\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[0;32m    353\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 354\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    356\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    357\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    358\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    359\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    364\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    365\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:354\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[0;32m    353\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 354\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    356\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    357\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    358\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    359\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    364\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    365\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:376\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    371\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m param \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    372\u001b[0m     \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    373\u001b[0m     \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    374\u001b[0m     \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    375\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 376\u001b[0m         param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    377\u001b[0m     should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    378\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:605\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[0;32m    604\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m--> 605\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 94.00 MiB (GPU 0; 2.00 GiB total capacity; 1.72 GiB already allocated; 0 bytes free; 1.73 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "# Create a ClassificationModel\n",
    "model = ClassificationModel('xlnet', 'xlnet-base-cased', args={'num_train_epochs':4, 'train_batch_size':32, 'max_seq_length':40}) # You can set class weights by using the optional weight argument\n",
    "\n",
    "# Train the model\n",
    "model.train_model(train_df)\n",
    "\n",
    "# Evaluate the model\n",
    "result, model_outputs, wrong_predictions = model.eval_model(eval_df, acc=sklearn.metrics.accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3678c16-0296-407a-9919-a04ec9af3b50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
